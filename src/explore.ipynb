{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import the libraries top use\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 1: Problem statement and data collection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils import load_data \n",
                "\n",
                "file_path = '../data/raw/file_name.csv'\n",
                "url = 'url_to_csv_file'\n",
                "\n",
                "df = load_data(file_path=file_path, url=url)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Problem to solve:\n",
                "\n",
                "We want to create a logistic classifier using the collected data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 2: Exploration and data cleaning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Eliminate duplicates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Eliminate irrelevant information"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 3: Analysis of univariate variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A **univariate variable** is a statistical term used to refer to a set of observations of an attribute. That is, the column-by-column analysis of the DataFrame. To do this, we must distinguish whether a variable is categorical or numerical, as the body of the analysis and the conclusions that can be drawn will be different."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analysis of categorical variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A **categorical variable** is a type of variable that can be one of a limited number of categories or groups. These groups are often nominal (e.g., the color of a car: red, blue, black, etc., but none of these colors is inherently \"greater\" or \"better\" than the others) but can also be represented by finite numbers.\n",
                "\n",
                "**To represent these types of variables we will use histograms.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analysis on numeric variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A **numeric variable** is a type of variable that can take numeric values (integers, fractions, decimals, negatives, etc.) in an infinite range. A numerical categorical variable can also be a numerical variable. \n",
                "\n",
                "**They are usually represented using a histogram and a boxplot, displayed together.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 4: Analysis of multivariate variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After analyzing the characteristics one by one, it is time to analyze them in relation to the predictor and to themselves, in order to draw clearer conclusions about their relationships and to be able to make decisions about their processing.\n",
                "\n",
                "Thus, if we would like to eliminate a variable due to a high amount of null values or certain outliers, it is necessary to first apply this process to ensure that the elimination of certain values are not critical for the survival of a passenger. For example, the variable Cabin has many null values, and we would have to ensure that there is no relationship between it and survival before eliminating it, since it could be very significant and important for the model and its presence could bias the prediction."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Numerical-numerical analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When the two variables being compared have numerical data, the analysis is said to be numerical-numerical. \n",
                "\n",
                "**Scatterplots and correlation analysis are used to compare two numerical columns.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Categorical-categorical analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When the two variables being compared have categorical data, the analysis is said to be categorical-categorical. \n",
                "\n",
                "**Histograms and combinations are used to compare two categorical columns.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combinations of class with various predictors"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Numerical-categorical analysis (complete)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 5: Feature engineering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Feature engineering is a process that involves the creation of new features (or variables) from existing ones to improve model performance. This may involve a variety of techniques, such as normalization, data transformation, and so on. The goal is to improve the accuracy of the model and/or reduce the complexity of the model, thus making it easier to interpret.\n",
                "\n",
                "Although this could have been done in this step as it is part of the feature engineering, it is usually done before analyzing the variables, separating this process into a previous one and the one we are going to see next."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Outlier analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "An outlier is a data point that deviates significantly from the others. It is a value that is noticeably different from what would be expected given the general trend of the data. These outliers may be caused by errors in data collection, natural variations in the data, or they may be indicative of something significant, such as an anomaly or extraordinary event.\n",
                "\n",
                "Descriptive analysis is a powerful tool for characterizing the data set: the mean, variance and quartiles provide powerful information about each variable. The describe() function of a DataFrame helps us to calculate in a very short time all these values."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Missing value analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A **missing** value is a space that has no value assigned to it in the observation of a specific variable. These types of values are quite common and can arise for many reasons. For example, there could be an error in data collection, someone may have refused to answer a question in a survey, or it could simply be that certain information is not available or not applicable."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Inference of new features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Another typical use of this engineering is to obtain new features by \"merging\" two or more existing ones."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Divide the set into train and test,"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature scaling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Feature scaling** is a crucial step in data preprocessing for many Machine Learning algorithms. It is a technique that changes the range of data values so that they can be compared to each other. Scaling usually involves normalization, which is the process of changing the values so that they have a mean of 0 and a standard deviation of 1. Another common technique is min-max scaling, which transforms the data so that all values are between 0 and 1."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 6: Feature selection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The feature selection is a process that involves selecting the most relevant features (variables) from our dataset to use in building a Machine Learning model, discarding the rest.\n",
                "\n",
                "There are several reasons to include it in our exploratory analysis:\n",
                "\n",
                "1. To simplify the model so that it is easier to understand and interpret.\n",
                "2. To reduce the training time of the model.\n",
                "3. Avoid overfitting by reducing the dimensionality of the model and minimizing noise and unnecessary correlations.\n",
                "4. Improve model performance by removing irrelevant features.\n",
                " \n",
                "In addition, there are several techniques for feature selection. Many of them are based on trained supervised or clustering models. More information is available here.\n",
                "\n",
                "The sklearn library contains many of the best alternatives to perform it. One of the most commonly used tools for fast and successful feature selection processes is SelectKBest. This function selects the k best features from our dataset based on a function of a statistical test. This statistical test is usually an ANOVA or a Chi-Square."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ds_venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
